import os
import time
import json
import requests
# timezone ì„í¬íŠ¸ ì¶”ê°€ (Python ë²„ì „ í˜¸í™˜ì„± í™•ë³´)
from datetime import datetime, timedelta, timezone
from urllib.parse import urljoin
from typing import List, Tuple, Dict
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor
import google.generativeai as genai
from dotenv import load_dotenv

# ----------------------------------------
# í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
# ----------------------------------------
load_dotenv()

# .strip()ì„ ì¶”ê°€í•˜ì—¬ í† í°ì´ë‚˜ ID ì•ë’¤ì˜ ëª¨ë“  ê³µë°±/íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "").strip()

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ëª¨ë¸ëª…ì€ ì‚¬ìš©ìì˜ ë¡œê·¸ì—ì„œ í™•ì¸ëœ 'gemini-2.0-flash'ë¡œ ê³ ì •
GEMINI_MODEL_NAME = 'gemini-2.0-flash' 

PRESS_LIST: List[Tuple[str, str]] = [
    ("ë™ì•„ì¼ë³´", "020"),
    ("í•œêµ­ì¼ë³´", "469"),
    ("ì¡°ì„ ì¼ë³´", "023"),
    ("ì¤‘ì•™ì¼ë³´", "025"),
    ("í•œê²¨ë ˆ", "028"),
    ("ê²½í–¥ì‹ ë¬¸", "032"),
]
# URL ì¡°í•©ì„ f-stringìœ¼ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# BASE_NEWPAPER_URL = "https://media.naver.com/press/{press}/newspaper?date={date}"

# ----------------------------------------
# [Part 1] ë„¤ì´ë²„ 1ë©´ ë§í¬ ìˆ˜ì§‘
# ----------------------------------------
def get_kst_today() -> str:
    # timezone.utcë¥¼ ì‚¬ìš©í•˜ì—¬ Python ë²„ì „ì— ê´€ê³„ì—†ì´ UTCë¥¼ ëª…í™•í•˜ê²Œ ì§€ì •
    now_utc = datetime.now(timezone.utc)
    now_kst = now_utc + timedelta(hours=9)
    return now_kst.strftime("%Y%m%d")

def fetch_html(url: str) -> str:
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    # URL ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ strip() ì ìš©
    resp = requests.get(url.strip(), headers=headers, timeout=20) 
    resp.raise_for_status()
    return resp.text

def extract_a1_links(html: str, page_url: str, press_code: str, date: str) -> List[str]:
    soup = BeautifulSoup(html, "html.parser")
    candidates: List[str] = []

    for a in soup.find_all("a", href=True):
        href = a["href"]
        if f"/article/newspaper/{press_code}/" not in href: continue
        if f"date={date}" not in href: continue
        full_url = urljoin(page_url, href)
        
        is_a1 = False
        parent = a
        for _ in range(6):
            parent = parent.parent
            if parent is None: break
            text = parent.get_text(" ", strip=True)
            if any(key in text for key in ["A1ë©´", "A01ë©´", "1ë©´", "1 é¢"]):
                is_a1 = True
                break
        if is_a1: candidates.append(full_url)

    if not candidates: # Fallback
        seen = set()
        for a in soup.find_all("a", href=True):
            href = a["href"]
            if f"/article/newspaper/{press_code}/" in href and f"date={date}" in href:
                full_url = urljoin(page_url, href)
                if full_url not in seen:
                    candidates.append(full_url)
                    seen.add(full_url)
            if len(candidates) >= 4: break
    return list(set(candidates))

def collect_naver_news_links() -> List[Dict[str, str]]:
    date = get_kst_today()
    print(f"[INFO] {date}ì¼ì 1ë©´ ê¸°ì‚¬ ìˆ˜ì§‘ ì‹œì‘")
    all_items = []
    for press_name, press_code in PRESS_LIST:
        url = "" # url ë³€ìˆ˜ ì´ˆê¸°í™”
        try:
            # f-stringì„ ì‚¬ìš©í•´ ëª…í™•í•˜ê²Œ URL ì¡°í•© (ì´ì „ ì˜¤ë¥˜ í•´ê²° ì½”ë“œ ë°˜ì˜)
            url = f"https://media.naver.com/press/{press_code}/newspaper?date={date}".strip()
            
            html = fetch_html(url)
            links = extract_a1_links(html, url, press_code, date)
            for link in links:
                all_items.append({"source": press_name, "url": link})
        except Exception as e:
            # ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥ ì‹œ URLì„ ê°™ì´ ì¶œë ¥
            print(f"  [ì—ëŸ¬] {press_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            print(f"  [URL] ìš”ì²­ ì‹¤íŒ¨ URL: {url}")
    return all_items

# ----------------------------------------
# [Part 2] ë³¸ë¬¸ í¬ë¡¤ë§
# ----------------------------------------
def fetch_single_article_content(item: dict) -> dict:
    try:
        resp = requests.get(item["url"], headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        selectors = ["div#dic_area", "div#newsEndContents", "div.newsct_article", "div#articleBodyContents"]
        content = ""
        for selector in selectors:
            node = soup.select_one(selector)
            if node:
                content = node.get_text("\n", strip=True)
                break
        return {
            "source": item["source"],
            "url": item["url"],
            "content": content[:4000] if content else "ë³¸ë¬¸ ì—†ìŒ" # ê¸¸ì´ ì œí•œ
        }
    except:
        return item

def fetch_contents_parallel(items: list) -> list:
    print(f"[INFO] ì´ {len(items)}ê°œ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘...")
    with ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(fetch_single_article_content, items))
    return results

# ----------------------------------------
# [Part 3] Gemini ë¶„ì„ (ë¦¬í¬íŠ¸ ì‘ì„±)
# ----------------------------------------
def analyze_with_gemini(articles: list) -> dict:
    print(f"[INFO] {GEMINI_MODEL_NAME} ë¶„ì„ ìš”ì²­ ì‹œì‘...")
    
    model = genai.GenerativeModel(
        model_name=GEMINI_MODEL_NAME,
        generation_config={"response_mime_type": "application/json"}
    )

    articles_text = ""
    for i, art in enumerate(articles):
        articles_text += f"[ID:{i}] ì–¸ë¡ ì‚¬:{art['source']} | ë‚´ìš©:{art['content'][:2000]}\n"

    # í†µí•© ê¸°ì‚¬ ë¶„ëŸ‰ ë° ìƒì„¸ ìš”êµ¬ì‚¬í•­ ê°•í™” í”„ë¡¬í”„íŠ¸
    prompt = f"""
    ë„ˆëŠ” ì „ë¬¸ ë‰´ìŠ¤ ì—ë””í„°ë‹¤. ì˜¤ëŠ˜ì ì‹ ë¬¸ 1ë©´ ê¸°ì‚¬ë“¤ì„ ì¢…í•©í•˜ì—¬ ê³ í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ë¼.
    
    [ìš”êµ¬ì‚¬í•­]
    1. ê¸°ì‚¬ë“¤ì„ ìœ ì‚¬í•œ ì£¼ì œ(ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ ë“±)ë¡œ ê·¸ë£¹í™”í•˜ë¼.
    2. **ì£¼ì œë³„ í†µí•© ê¸°ì‚¬ ì‘ì„±**: ê° ì£¼ì œì— ëŒ€í•´ ê°œë³„ ê¸°ì‚¬ë¥¼ ë‹¨ìˆœíˆ ë‚˜ì—´í•˜ì§€ ë§ê³ , ëª¨ë“  ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ **í•˜ë‚˜ì˜ ì™„ê²°ëœ ì‹¬ì¸µ ê¸°ì‚¬**ë¡œ ìƒˆë¡œ ì¨ë¼.
        - **ë¶„ëŸ‰**: ë°˜ë“œì‹œ **ìµœì†Œ 500ì ì´ìƒ**ì˜ ìƒì„¸í•œ ê¸€ë¡œ ì‘ì„±í•  ê²ƒ.
        - **êµ¬ì„±**: ê¸°ì‚¬ì˜ ë°°ê²½, í˜„ì¬ ìƒí™©, ì–¸ë¡ ì‚¬ë³„ ì£¼ìš” ì£¼ì¥, ê·¸ë¦¬ê³  í–¥í›„ ì „ë§ì´ë‚˜ ì „ë¬¸ê°€ ë¶„ì„ ë“± ë‹¤ê°ë„ì˜ ê´€ì ì„ í¬í•¨í•˜ì—¬ ì‘ì„±í•  ê²ƒ.
        - **í†¤**: ì „ë¬¸ê°€ê°€ ì‘ì„±í•œ ê°ê´€ì ì¸ ë…¼ì¡°ì˜ ê¸°ì‚¬ í˜•íƒœë¥¼ ìœ ì§€í•  ê²ƒ.
    3. **ìš”ì•½ë³¸(Bullets)**: ë°”ìœ ë…ìë¥¼ ìœ„í•´, í†µí•© ê¸°ì‚¬ì˜ ë‚´ìš©ì„ 3ì¤„ ì´ë‚´ì˜ í•µì‹¬ ë‹¨ë¬¸(Bullet point)ìœ¼ë¡œ ìš”ì•½í•˜ë¼.
    4. ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ì´ì–´ì•¼ í•œë‹¤.

    [JSON êµ¬ì¡°]
    {{
        "topics": [
            {{
                "title": "ì£¼ì œ ì œëª© (ì˜ˆ: ê¸ˆíˆ¬ì„¸ íì§€ ë…¼ë€ ê°€ì—´)",
                "ids": [0, 2, 5],
                "summary_bullets": ["í•µì‹¬ ë‚´ìš© 1", "í•µì‹¬ ë‚´ìš© 2"],
                "full_article": "ì—¬ê¸°ì— GPTê°€ ìƒˆë¡œ ì‘ì„±í•œ í†µí•© ê¸°ì‚¬ ì „ë¬¸(ì¤„ê¸€ë¡œ ì‘ì„±). 500ì ì´ìƒì„ ì±„ìš°ë„ë¡ ë…¸ë ¥í•´ì•¼ í•œë‹¤."
            }}
        ]
    }}

    [ê¸°ì‚¬ ë°ì´í„°]
    {articles_text}
    """

    response = None

    try:
        response = model.generate_content(prompt)
        raw_text = response.text.strip()
        
        # JSON ì‘ë‹µì„ ê°ì‹¸ëŠ” ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        if raw_text.startswith('```json'):
            raw_text = raw_text.removeprefix('```json').removesuffix('```').strip()
        
        return json.loads(raw_text)
        
    except json.JSONDecodeError as e:
        # JSON ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ: ëª¨ë¸ì´ ìƒì„±í•œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print(f"[CRITICAL ERROR] JSON ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        print("--- Gemini Raw Output Start ---")
        if response:
            print(response.text)
        else:
            print("No response object available.")
        print("--- Gemini Raw Output End ---")
        return {"topics": []}
    
    except Exception as e:
        print(f"[CRITICAL ERROR] Gemini ë¶„ì„ ì¤‘ ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ: {e}")
        return {"topics": []}

# ----------------------------------------
# [Part 4] Telegraph í˜ì´ì§€ ìƒì„± (ì›¹ë·°)
# ----------------------------------------
def create_telegraph_simple(title: str, text_body: str) -> str:
    """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ Telegraph í˜ì´ì§€ ìƒì„±"""
    try:
        # 1. í† í° ìƒì„±: URL ê¹¨ë—í•˜ê²Œ ìœ ì§€ (ìˆ˜ì •ë¨)
        telegraph_account_url = "[https://api.telegra.ph/createAccount?short_name=NewsAI](https://api.telegra.ph/createAccount?short_name=NewsAI)"
        print(f"[DEBUG] Telegraph Account URL: {telegraph_account_url}")
        
        r = requests.get(telegraph_account_url).json()
        token = r['result']['access_token']
        
        content_nodes = []
        content_nodes.append({"tag": "h3", "children": ["AI í†µí•© ë¦¬í¬íŠ¸"]})
        
        current_p_children = []
        for line in text_body.split('\n'):
            line = line.strip()
            if not line and current_p_children:
                content_nodes.append({"tag": "p", "children": current_p_children})
                current_p_children = []
            elif line:
                current_p_children.append(line)
        
        if current_p_children:
            content_nodes.append({"tag": "p", "children": current_p_children})
        
        data = {
            "access_token": token,
            "title": title,
            "content": json.dumps(content_nodes),
            "return_content": False
        }
        # 2. í˜ì´ì§€ ìƒì„±: URL ê¹¨ë—í•˜ê²Œ ìœ ì§€ (ìˆ˜ì •ë¨)
        telegraph_create_page_url = "[https://api.telegra.ph/createPage](https://api.telegra.ph/createPage)"
        resp = requests.post(telegraph_create_page_url, data=data).json()
        
        if resp.get('ok'):
            return resp['result']['url']
        else:
            print(f"Telegraph API ì˜¤ë¥˜: {resp.get('error')}")
            return ""
    except Exception as e:
        # ì´ ì‹œì ì—ì„œ InvalidSchemaê°€ ë°œìƒí•˜ë©´ Telegraph URL ìì²´ì˜ ë¬¸ìì—´ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ 100%
        print(f"Telegraph ìƒì„± ì‹¤íŒ¨: {e}")
        return ""

# ----------------------------------------
# [Part 5] í…”ë ˆê·¸ë¨ ì „ì†¡ (HTML ëª¨ë“œ)
# ----------------------------------------
def send_telegram(message: str):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: 
        print("[WARNING] í…”ë ˆê·¸ë¨ í† í° ë˜ëŠ” ì±„íŒ… IDê°€ ì—†ì–´ ì „ì†¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return
        
    # URL êµ¬ì„±: URL ê¹¨ë—í•˜ê²Œ ìœ ì§€ (ìˆ˜ì •ë¨)
    url = f"[https://api.telegram.org/bot](https://api.telegram.org/bot){TELEGRAM_BOT_TOKEN}/sendMessage"
    
    # ğŸš¨ ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€: URL ê¸¸ì´ë¥¼ ì¶œë ¥í•˜ê³ , í† í°ì´ ì‚½ì…ëœ URLì˜ ì•ë¶€ë¶„ì„ í™•ì¸
    # í† í°ì— ë¬¸ì œê°€ ìˆë‹¤ë©´ URL ê¸¸ì´ê°€ ë¹„ì •ìƒì ì´ê±°ë‚˜, URLì— ì´ìƒí•œ ë¬¸ìê°€ ë³´ì¼ ìˆ˜ ìˆìŒ.
    # ì•ˆì „ì„ ìœ„í•´ í† í° ë¶€ë¶„ì€ *ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ì¶œë ¥
    masked_url = url.replace(TELEGRAM_BOT_TOKEN, "***masked***")
    print(f"[DEBUG] Telegram URL length: {len(url)}")
    print(f"[DEBUG] Telegram URL fragment (masked): {masked_url[:70]}")
    
    chunk_size = 4000 
    for i in range(0, len(message), chunk_size):
        payload = {
            "chat_id": TELEGRAM_CHAT_ID, 
            "text": message[i:i+chunk_size], 
            "parse_mode": "HTML", 
            "disable_web_page_preview": True 
        }
        requests.post(url, data=payload)
        time.sleep(0.5)

# ----------------------------------------
# ë©”ì¸ ì‹¤í–‰
# ----------------------------------------
def main():
    # 1. ë§í¬ ìˆ˜ì§‘ ë° í†µê³„
    links = collect_naver_news_links()
    if not links: 
        print("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ì–¸ë¡ ì‚¬ë³„ ìˆ˜ëŸ‰ ì¹´ìš´íŠ¸
    stats = {}
    for item in links:
        stats[item['source']] = stats.get(item['source'], 0) + 1
    
    # í†µê³„ í—¤ë” ìƒì„±
    header_stats = " | ".join([f"{k} {v}" for k, v in stats.items()])

    # 2. ë³¸ë¬¸ í¬ë¡¤ë§
    contents = fetch_contents_parallel(links)

    # 3. Gemini ë¶„ì„
    if not GEMINI_API_KEY: 
        print("API í‚¤ê°€ ì—†ì–´ ë¶„ì„ì„ ìƒëµí•©ë‹ˆë‹¤.")
        return
    
    result = analyze_with_gemini(contents)
    
    # 4. ë¦¬í¬íŠ¸ ë° ì›¹ë·° ì»¨í…ì¸  ìƒì„±
    today_str = get_kst_today()
    
    # í…”ë ˆê·¸ë¨ìš© ë©”ì‹œì§€ (ìš”ì•½ ìœ„ì£¼)
    telegram_msg = f"<b>ğŸ— {today_str} ì‹ ë¬¸ 1ë©´ ë¸Œë¦¬í•‘</b>\n\n"
    telegram_msg += f"ğŸ“Š <b>ìˆ˜ì§‘ í˜„í™©:</b> {header_stats}\n\n"
    
    # ì›¹ë·°ìš© ì „ì²´ í…ìŠ¤íŠ¸
    webview_text = f"ğŸ“° {today_str} ì‹ ë¬¸ 1ë©´ í†µí•© ë¦¬í¬íŠ¸\n\n[ìˆ˜ì§‘ í˜„í™©] {header_stats}\n\n"

    topics = result.get("topics", [])
    
    # === [ìš”ì²­ ì‚¬í•­ ë°˜ì˜: ì£¼ì œë³„ ê¸°ì‚¬ ìˆ˜ì— ë”°ë¼ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬] ===
    # 'ids' ë¦¬ìŠ¤íŠ¸ì˜ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    topics.sort(key=lambda t: len(t.get('ids', [])), reverse=True)
    # =========================================================
    
    if not topics:
        telegram_msg += "<b>âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: ë¶„ì„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜, AIê°€ ë‹µë³€ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. GitHub Actions ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.</b>"
        webview_text = "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨"
    else:
        for topic in topics:
            title = topic.get('title', 'ë¬´ì œ')
            ids = topic.get('ids', [])
            bullets = topic.get('summary_bullets', [])
            full_article = topic.get('full_article', '')

            # --- í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ êµ¬ì„± ---
            telegram_msg += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            telegram_msg += f"ğŸ“Œ <b>{title}</b> ({len(ids)}ê±´)\n"
            
            link_tags = []
            for idx in ids:
                if idx < len(contents):
                    item = contents[idx]
                    link_tags.append(f"<a href='{item['url']}'>{item['source']}</a>")
            telegram_msg += f"ğŸ”— {' , '.join(link_tags)}\n\n"
            
            for bullet in bullets:
                telegram_msg += f"â€¢ {bullet}\n"
            telegram_msg += "\n"

            # --- ì›¹ë·° í…ìŠ¤íŠ¸ êµ¬ì„± ---
            webview_text += f"\n### ğŸ“Œ {title} ({len(ids)}ê±´)\n"
            webview_text += "\n[í•µì‹¬ ìš”ì•½]\n"
            for bullet in bullets:
                webview_text += f" - {bullet}\n"
            webview_text += "\n[í†µí•© ì‹¬ì¸µ ê¸°ì‚¬]\n"
            webview_text += f"{full_article}\n"
            webview_text += "\n\n"

    # 5. Telegraph í˜ì´ì§€ ìƒì„± (ê¸´ í™”ë©´ìš©)
    webview_url = create_telegraph_simple(f"{today_str} ì¡°ê°„ ë¸Œë¦¬í•‘", webview_text)
    
    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í•˜ë‹¨ì— ë§í¬ ì¶”ê°€
    if webview_url:
        telegram_msg += f"\n\nğŸ“± <b><a href='{webview_url}'>ğŸ‘‰ ì „ì²´ ë¦¬í¬íŠ¸ í¬ê²Œ ë³´ê¸° (Safari/Web)</a></b>"

    # 6. ì „ì†¡
    print("[INFO] í…”ë ˆê·¸ë¨ ì „ì†¡ ì¤‘...")
    send_telegram(telegram_msg)
    print("[INFO] ì™„ë£Œ.")

if __name__ == "__main__":
    main()
